{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DB matching\n",
    "Simple database matching tool using cosine and weighted cosine similarities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "base = \"data\"\n",
    "dataset = \"nist\"\n",
    "kind = \"in_database\"\n",
    "\n",
    "data_train_path =f\"{base}/{dataset}/{kind}/train.msp\"\n",
    "data_val_path =f\"{base}/{dataset}/{kind}/val.msp\"\n",
    "data_test_path =f\"{base}/{dataset}/{kind}/test.msp\"\n",
    "\n",
    "max_mz = 1001\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matchms.importing import load_from_msp\n",
    "from msai.data import spectrum_processing, get_n_samples\n",
    "from msai.utils import get_mz_vector\n",
    "from numpy.random import default_rng\n",
    "from scipy.sparse import csr_matrix\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_spectra(path):\n",
    "    # Load data from MSP file and apply filters\n",
    "    spectrums = [spectrum_processing(s, min_rel_int=None) for s in load_from_msp(path)]\n",
    "    # Omit spectrums that didn't qualify for analysis\n",
    "    spectrums = [s for s in spectrums if s is not None]\n",
    "    # Create spectrum documents\n",
    "    return spectrums\n",
    "spectrums_train = get_spectra(data_train_path)\n",
    "spectrums_val = get_spectra(data_val_path)\n",
    "spectrums_test = get_spectra(data_test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = {\n",
    "    \"spec_train\": spectrums_train, \n",
    "    \"spec_val\": spectrums_val, \n",
    "    \"spec_val_5000\": get_n_samples(spectrums_val, 5000),\n",
    "    \"spec_val_10000\": get_n_samples(spectrums_val, 10000),\n",
    "    \"spec_test\": spectrums_test, \n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Database matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "mz_matrix_train = np.zeros(shape=(len(spectrums_train), max_mz))\n",
    "for i, spec in enumerate(spectrums_train):\n",
    "    mz_matrix_train[i] = get_mz_vector(spec, max_mz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get matrix for weighted cosine score\n",
    "def get_weighted(matrix):\n",
    "    n_sam =matrix.shape[0] \n",
    "    n_mz = matrix.shape[1]\n",
    "    factors = np.tile(np.arange(n_mz), n_sam).reshape(n_sam, -1) + 1\n",
    "    return (matrix**0.5) * factors\n",
    "\n",
    "weighted_cosine_mz_matrix = get_weighted(mz_matrix_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse_weighted_mz_matrix = csr_matrix(weighted_cosine_mz_matrix)\n",
    "sparse_mz_matrix = csr_matrix(mz_matrix_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import NearestNeighbors\n",
    "class BaseMatcherKNN():\n",
    "    def __init__(self, sparse_weighted_mz_matrix, max_mz=1001, is_weighted=False):\n",
    "        self.sparse_weighted_mz_matrix = sparse_weighted_mz_matrix\n",
    "        self.rng = default_rng(42)\n",
    "        self.max_mz = max_mz\n",
    "        self.is_weighted = is_weighted\n",
    "        \n",
    "        self.neigh = NearestNeighbors(n_neighbors=50, n_jobs=32, metric=\"cosine\")\n",
    "        self.neigh.fit(self.sparse_weighted_mz_matrix)\n",
    "    \n",
    "    def match_topk_all(self, spectrums_ref, spectrums, up_to_k, n, limit=100000):\n",
    "\n",
    "        n_pred_ikeys_per_k = [[None for _ in range(len(spectrums[:limit]))] for _ in range(up_to_k)]\n",
    "        y_ikeys = []\n",
    "        for i, spec in enumerate(spectrums[:limit]):\n",
    "            vect = get_mz_vector(spec, self.max_mz)\n",
    "            \n",
    "            m = np.zeros(shape=(up_to_k,vect.shape[0]))\n",
    "            \n",
    "            descending = np.argsort(spec.peaks.intensities)[::-1]\n",
    "            y_ikeys.append(spec.metadata[\"inchikey\"].split(\"-\")[0])\n",
    "\n",
    "            skipped = np.zeros(up_to_k) == 1\n",
    "            \n",
    "            for j in range(1, up_to_k+1):\n",
    "                \n",
    "                if len(spec.peaks.mz) <= j:\n",
    "                    skipped[j-1] = True\n",
    "                    continue\n",
    "                    \n",
    "                val_at_jth = spec.peaks.intensities[descending][j-1]\n",
    "                \n",
    "                    \n",
    "                ## cripple vector\n",
    "                m[j-1] = vect.copy()                    \n",
    "                m[j-1][m[j-1] < val_at_jth] = 0\n",
    "            \n",
    "            if self.is_weighted:\n",
    "                weighted = csr_matrix(get_weighted(m))\n",
    "            else:\n",
    "                weighted = csr_matrix(m)\n",
    "                \n",
    "            sim = cosine_similarity(weighted, self.sparse_weighted_mz_matrix)\n",
    "            \n",
    "            for j in range(1, up_to_k+1):\n",
    "                if skipped[j-1]:\n",
    "                    continue\n",
    "\n",
    "                top_n_sindices = np.argsort(sim[j-1])[::-1][:n]\n",
    "\n",
    "                top_n_ikeys = [spectrums_ref[i].metadata[\"inchikey\"].split(\"-\")[0] for i in top_n_sindices]\n",
    "                n_pred_ikeys_per_k[j-1][i] = top_n_ikeys\n",
    "            \n",
    "        return n_pred_ikeys_per_k, y_ikeys\n",
    "    \n",
    "    def match_random_all(self, spectrums_ref, spectrums, probs, n, cum_level=.95, limit=100000):\n",
    "        self.rng = default_rng(42)\n",
    "        \n",
    "        n_pred_ikeys_per_p = [[None for _ in range(len(spectrums[:limit]))] for _ in range(len(probs))]\n",
    "        y_ikeys = []\n",
    "        for i, spec in enumerate(spectrums[:limit]):\n",
    "            \n",
    "            vect = get_mz_vector(spec, self.max_mz)            \n",
    "            mat = np.zeros(shape=(len(probs),vect.shape[0]))\n",
    "            \n",
    "            y_ikeys.append(spec.metadata[\"inchikey\"].split(\"-\")[0])\n",
    "                      \n",
    "            for m, p in enumerate(probs):        \n",
    "                \n",
    "                ## cripple vector\n",
    "                mat[m] = vect.copy()\n",
    "                                \n",
    "                mask_missing = self.rng.uniform(0,1,self.max_mz) < p\n",
    "                \n",
    "                mat[m][mask_missing] = 0\n",
    "            \n",
    "            if self.is_weighted:\n",
    "                weighted = csr_matrix(get_weighted(mat))\n",
    "            else:\n",
    "                weighted = csr_matrix(mat)\n",
    "            \n",
    "            top_n = self.neigh.kneighbors(weighted, n_neighbors=n, return_distance=False)\n",
    "            for m, p in enumerate(probs): \n",
    "                \n",
    "                top_n_sindices = top_n[m]\n",
    "                top_n_ikeys = [spectrums_ref[i].metadata[\"inchikey\"].split(\"-\")[0] for i in top_n_sindices]\n",
    "                n_pred_ikeys_per_p[m][i] = top_n_ikeys\n",
    "            \n",
    "        return n_pred_ikeys_per_p, y_ikeys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "up_to_k = 30\n",
    "\n",
    "probs = [0, .01, .03, .05, .08, .1, .15, .2, .3, .5]\n",
    "\n",
    "to_match = 50\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "matcher = BaseMatcherKNN(sparse_mz_matrix, max_mz=max_mz, is_weighted=False)\n",
    "\n",
    "tested = \"spec_val\"\n",
    "p_name = \"cosine\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "n_pred_ikeys_per_k, y_ikeys = matcher.match_topk_all(datasets[\"spec_train\"], datasets[tested], \\\n",
    "                                                     up_to_k, to_match)\n",
    "np.save(f\"matches/{kind}/{dataset}/{tested}/{p_name}/n_pred_ikeys_per_k.npy\", n_pred_ikeys_per_k)\n",
    "np.save(f\"matches/{kind}/{dataset}/{tested}/{p_name}/y_ikeys.npy\", y_ikeys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 9h 57min 6s, sys: 54min 30s, total: 10h 51min 37s\n",
      "Wall time: 3h 45min 56s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "n_pred_ikeys_per_p, y_ikeys = matcher.match_random_all(datasets[\"spec_train\"], datasets[tested], \\\n",
    "                                                       probs, to_match)\n",
    "np.save(f\"matches/{kind}/{dataset}/{tested}/{p_name}/n_pred_ikeys_per_p.npy\", n_pred_ikeys_per_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "matcher_weighted = BaseMatcherKNN(sparse_weighted_mz_matrix, max_mz=max_mz, is_weighted=True)\n",
    "\n",
    "tested = \"spec_val\"\n",
    "p_name = \"cosine_weighted\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "n_pred_ikeys_per_k, y_ikeys = matcher_weighted.match_topk_all(datasets[\"spec_train\"], \\\n",
    "                                                              datasets[tested], up_to_k, to_match)\n",
    "np.save(f\"matches/{kind}/{dataset}/{tested}/{p_name}/n_pred_ikeys_per_k.npy\", n_pred_ikeys_per_k)\n",
    "np.save(f\"matches/{kind}/{dataset}/{tested}/{p_name}/y_ikeys.npy\", y_ikeys)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 9h 53min, sys: 1h 1min 43s, total: 10h 54min 44s\n",
      "Wall time: 4h 2min 26s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "n_pred_ikeys_per_p, y_ikeys = matcher_weighted.match_random_all(datasets[\"spec_train\"], \\\n",
    "                                                                datasets[tested], probs, to_match)\n",
    "np.save(f\"matches/{kind}/{dataset}/{tested}/{p_name}/n_pred_ikeys_per_p.npy\", n_pred_ikeys_per_p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_for_top(top, n_pred_ikeys_per_k, y_ikeys):\n",
    "    for k in range(len(n_pred_ikeys_per_k)):\n",
    "        corr = 0\n",
    "        tot = 0\n",
    "        for i in range(len(y_ikeys)):\n",
    "            if n_pred_ikeys_per_k[k][i] is None:\n",
    "                #print(\"short\")\n",
    "                continue\n",
    "            if y_ikeys[i] in n_pred_ikeys_per_k[k][i][:top]:\n",
    "                corr += 1\n",
    "            tot += 1\n",
    "\n",
    "        print(f\"For k={k+1}, {corr/tot*100:.0f}% - {corr}/{tot} was recovered in top {top}\")\n",
    "        \n",
    "def show_for_random(top, probs, n_pred_ikeys_per_m, y_ikeys):\n",
    "    for m, p in enumerate(probs):\n",
    "        corr = 0\n",
    "        tot = 0\n",
    "        for i in range(len(y_ikeys)):\n",
    "            if n_pred_ikeys_per_m[m][i] is None:\n",
    "                print(\"short\")\n",
    "                continue\n",
    "            if y_ikeys[i] in n_pred_ikeys_per_m[m][i][:top]:\n",
    "                corr += 1\n",
    "            tot += 1\n",
    "\n",
    "        print(f\"For p={p}, {corr/tot*100:.0f}% - {corr}/{tot} was recovered in top {top}\")\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Cosine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "tested = \"spec_val\"\n",
    "p_name = \"cosine\"\n",
    "\n",
    "n_pred_ikeys_per_p = np.load(f\"matches/{kind}/{dataset}/{tested}/{p_name}/n_pred_ikeys_per_p.npy\")\n",
    "n_pred_ikeys_per_k = np.load(f\"matches/{kind}/{dataset}/{tested}/{p_name}/n_pred_ikeys_per_k.npy\", allow_pickle=True)\n",
    "y_ikeys = np.load(f\"matches/{kind}/{dataset}/{tested}/{p_name}/y_ikeys.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For k=1, 0% - 38/22921 was recovered in top 1\n",
      "For k=2, 8% - 1846/22921 was recovered in top 1\n",
      "For k=3, 24% - 5566/22921 was recovered in top 1\n",
      "For k=4, 38% - 8704/22921 was recovered in top 1\n",
      "For k=5, 48% - 10947/22921 was recovered in top 1\n",
      "For k=6, 54% - 12266/22921 was recovered in top 1\n",
      "For k=7, 58% - 13182/22921 was recovered in top 1\n",
      "For k=8, 60% - 13768/22921 was recovered in top 1\n",
      "For k=9, 62% - 14187/22921 was recovered in top 1\n",
      "For k=10, 63% - 14488/22884 was recovered in top 1\n",
      "For k=11, 64% - 14690/22854 was recovered in top 1\n",
      "For k=12, 65% - 14888/22818 was recovered in top 1\n",
      "For k=13, 66% - 15003/22771 was recovered in top 1\n",
      "For k=14, 66% - 15085/22714 was recovered in top 1\n",
      "For k=15, 67% - 15110/22640 was recovered in top 1\n",
      "For k=16, 67% - 15142/22575 was recovered in top 1\n",
      "For k=17, 67% - 15144/22507 was recovered in top 1\n",
      "For k=18, 67% - 15128/22415 was recovered in top 1\n",
      "For k=19, 68% - 15093/22305 was recovered in top 1\n",
      "For k=20, 68% - 15071/22206 was recovered in top 1\n",
      "For k=21, 68% - 14995/22070 was recovered in top 1\n",
      "For k=22, 68% - 14928/21926 was recovered in top 1\n",
      "For k=23, 68% - 14854/21777 was recovered in top 1\n",
      "For k=24, 68% - 14764/21630 was recovered in top 1\n",
      "For k=25, 68% - 14685/21453 was recovered in top 1\n",
      "For k=26, 68% - 14576/21291 was recovered in top 1\n",
      "For k=27, 69% - 14449/21091 was recovered in top 1\n",
      "For k=28, 69% - 14341/20896 was recovered in top 1\n",
      "For k=29, 69% - 14222/20708 was recovered in top 1\n",
      "For k=30, 69% - 14080/20524 was recovered in top 1\n"
     ]
    }
   ],
   "source": [
    "show_for_top(1, n_pred_ikeys_per_k, y_ikeys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For p=0, 69% - 15793/22921 was recovered in top 1\n",
      "For p=0.01, 67% - 15459/22921 was recovered in top 1\n",
      "For p=0.03, 65% - 14823/22921 was recovered in top 1\n",
      "For p=0.05, 62% - 14109/22921 was recovered in top 1\n",
      "For p=0.08, 58% - 13209/22921 was recovered in top 1\n",
      "For p=0.1, 55% - 12624/22921 was recovered in top 1\n",
      "For p=0.15, 48% - 11115/22921 was recovered in top 1\n",
      "For p=0.2, 42% - 9597/22921 was recovered in top 1\n",
      "For p=0.3, 30% - 6778/22921 was recovered in top 1\n",
      "For p=0.5, 12% - 2797/22921 was recovered in top 1\n"
     ]
    }
   ],
   "source": [
    "show_for_random(1, probs, n_pred_ikeys_per_p, y_ikeys)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Weighted cosine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "tested = \"spec_val\"\n",
    "p_name = \"cosine_weighted\"\n",
    "\n",
    "n_pred_ikeys_per_p = np.load(f\"matches/{kind}/{dataset}/{tested}/{p_name}/n_pred_ikeys_per_p.npy\")\n",
    "n_pred_ikeys_per_k = np.load(f\"matches/{kind}/{dataset}/{tested}/{p_name}/n_pred_ikeys_per_k.npy\", allow_pickle=True)\n",
    "y_ikeys = np.load(f\"matches/{kind}/{dataset}/{tested}/{p_name}/y_ikeys.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For k=1, 0% - 50/22921 was recovered in top 1\n",
      "For k=2, 5% - 1039/22921 was recovered in top 1\n",
      "For k=3, 13% - 3025/22921 was recovered in top 1\n",
      "For k=4, 22% - 5134/22921 was recovered in top 1\n",
      "For k=5, 30% - 6962/22921 was recovered in top 1\n",
      "For k=6, 37% - 8574/22921 was recovered in top 1\n",
      "For k=7, 43% - 9841/22921 was recovered in top 1\n",
      "For k=8, 48% - 10928/22921 was recovered in top 1\n",
      "For k=9, 52% - 11872/22921 was recovered in top 1\n",
      "For k=10, 55% - 12641/22884 was recovered in top 1\n",
      "For k=11, 58% - 13292/22854 was recovered in top 1\n",
      "For k=12, 61% - 13870/22818 was recovered in top 1\n",
      "For k=13, 63% - 14297/22771 was recovered in top 1\n",
      "For k=14, 65% - 14711/22714 was recovered in top 1\n",
      "For k=15, 67% - 15062/22640 was recovered in top 1\n",
      "For k=16, 68% - 15339/22575 was recovered in top 1\n",
      "For k=17, 69% - 15598/22507 was recovered in top 1\n",
      "For k=18, 70% - 15758/22415 was recovered in top 1\n",
      "For k=19, 71% - 15910/22305 was recovered in top 1\n",
      "For k=20, 72% - 16058/22206 was recovered in top 1\n",
      "For k=21, 73% - 16135/22070 was recovered in top 1\n",
      "For k=22, 74% - 16171/21926 was recovered in top 1\n",
      "For k=23, 74% - 16215/21777 was recovered in top 1\n",
      "For k=24, 75% - 16237/21630 was recovered in top 1\n",
      "For k=25, 75% - 16188/21453 was recovered in top 1\n",
      "For k=26, 76% - 16154/21291 was recovered in top 1\n",
      "For k=27, 76% - 16105/21091 was recovered in top 1\n",
      "For k=28, 77% - 16062/20896 was recovered in top 1\n",
      "For k=29, 77% - 15996/20708 was recovered in top 1\n",
      "For k=30, 77% - 15906/20524 was recovered in top 1\n"
     ]
    }
   ],
   "source": [
    "show_for_top(1, n_pred_ikeys_per_k, y_ikeys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For p=0, 84% - 19202/22921 was recovered in top 1\n",
      "For p=0.01, 83% - 18959/22921 was recovered in top 1\n",
      "For p=0.03, 80% - 18402/22921 was recovered in top 1\n",
      "For p=0.05, 78% - 17932/22921 was recovered in top 1\n",
      "For p=0.08, 75% - 17154/22921 was recovered in top 1\n",
      "For p=0.1, 73% - 16655/22921 was recovered in top 1\n",
      "For p=0.15, 67% - 15287/22921 was recovered in top 1\n",
      "For p=0.2, 60% - 13838/22921 was recovered in top 1\n",
      "For p=0.3, 48% - 10889/22921 was recovered in top 1\n",
      "For p=0.5, 23% - 5197/22921 was recovered in top 1\n"
     ]
    }
   ],
   "source": [
    "show_for_random(1, probs, n_pred_ikeys_per_p, y_ikeys)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "up_to_k = 30\n",
    "\n",
    "probs = [0, .05, .1, .15, .2, .25, .3, .35, .4, .45, .5]\n",
    "\n",
    "to_match = 50\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "matcher = BaseMatcherKNN(sparse_mz_matrix, max_mz=max_mz, is_weighted=False)\n",
    "\n",
    "tested = \"spec_test\"\n",
    "p_name = \"cosine\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/numpy/core/_asarray.py:136: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  return array(a, dtype, copy=False, order=order, subok=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8h 10min 11s, sys: 59min 3s, total: 9h 9min 14s\n",
      "Wall time: 9h 9min 20s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "n_pred_ikeys_per_k, y_ikeys = matcher.match_topk_all(datasets[\"spec_train\"], datasets[tested], \\\n",
    "                                                     up_to_k, to_match)\n",
    "np.save(f\"matches/{kind}/{dataset}/{tested}/{p_name}/n_pred_ikeys_per_k.npy\", n_pred_ikeys_per_k)\n",
    "np.save(f\"matches/{kind}/{dataset}/{tested}/{p_name}/y_ikeys.npy\", y_ikeys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8h 58min 22s, sys: 47min 26s, total: 9h 45min 48s\n",
      "Wall time: 3h 24min 32s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "n_pred_ikeys_per_p, y_ikeys = matcher.match_random_all(datasets[\"spec_train\"], datasets[tested], \\\n",
    "                                                       probs, to_match)\n",
    "np.save(f\"matches/{kind}/{dataset}/{tested}/{p_name}/n_pred_ikeys_per_p.npy\", n_pred_ikeys_per_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "matcher_weighted = BaseMatcherKNN(sparse_weighted_mz_matrix, max_mz=max_mz, is_weighted=True)\n",
    "\n",
    "tested = \"spec_test\"\n",
    "p_name = \"cosine_weighted\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8h 22min 50s, sys: 58min 36s, total: 9h 21min 27s\n",
      "Wall time: 9h 21min 33s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "n_pred_ikeys_per_k, y_ikeys = matcher_weighted.match_topk_all(datasets[\"spec_train\"], \\\n",
    "                                                              datasets[tested], up_to_k, to_match)\n",
    "np.save(f\"matches/{kind}/{dataset}/{tested}/{p_name}/n_pred_ikeys_per_k.npy\", n_pred_ikeys_per_k)\n",
    "np.save(f\"matches/{kind}/{dataset}/{tested}/{p_name}/y_ikeys.npy\", y_ikeys)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8h 59min 58s, sys: 48min 33s, total: 9h 48min 32s\n",
      "Wall time: 3h 27min 14s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "n_pred_ikeys_per_p, y_ikeys = matcher_weighted.match_random_all(datasets[\"spec_train\"], \\\n",
    "                                                                datasets[tested], probs, to_match)\n",
    "np.save(f\"matches/{kind}/{dataset}/{tested}/{p_name}/n_pred_ikeys_per_p.npy\", n_pred_ikeys_per_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}